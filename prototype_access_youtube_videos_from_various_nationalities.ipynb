{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prototype_access_youtube_videos_from_various_nationalities.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmKY+dEVRDSvlGqKHfNObm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/El-Nico/accent-classification-using-scraped-youtube-data-CCT-capstone-project/blob/main/prototype_access_youtube_videos_from_various_nationalities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# !pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz00DP5IAvQM",
        "outputId": "5be44b26-cc71-4ffa-a81b-1e4d00240c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHmB7ubRBOfc",
        "outputId": "f702a602-2436-4687-9c9a-9945e2b20e21"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.1.0-py3-none-any.whl (958 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 378 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 389 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 399 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 409 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 419 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 430 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 440 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 450 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 460 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 471 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 481 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 491 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 501 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 512 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 522 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 532 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 542 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 552 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 563 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 573 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 583 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 593 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 604 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 614 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 624 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 634 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 645 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 655 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 665 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 675 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 686 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 696 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 706 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 716 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 727 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 737 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 747 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 757 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 768 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 778 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 788 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 798 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 808 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 819 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 829 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 839 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 849 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 860 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 870 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 880 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 890 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 901 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 911 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 921 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 931 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 942 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 952 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 958 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting urllib3[secure]~=1.26\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 65.5 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
            "\u001b[K     |████████████████████████████████| 359 kB 61.0 MB/s \n",
            "\u001b[?25hCollecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (3.10.0.2)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.8 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-36.0.1 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.0 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 urllib3-1.26.8 wsproto-1.0.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,827 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [806 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,252 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,594 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [937 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [840 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,035 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,474 kB]\n",
            "Get:24 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.8 kB]\n",
            "Fetched 14.1 MB in 3s (4,754 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 66 not upgraded.\n",
            "Need to get 95.3 MB of archives.\n",
            "After this operation, 327 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 97.0.4692.71-0ubuntu0.18.04.1 [1,142 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 97.0.4692.71-0ubuntu0.18.04.1 [84.7 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 97.0.4692.71-0ubuntu0.18.04.1 [4,370 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 97.0.4692.71-0ubuntu0.18.04.1 [5,055 kB]\n",
            "Fetched 95.3 MB in 5s (17.6 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155320 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_97.0.4692.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_97.0.4692.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_97.0.4692.71-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_97.0.4692.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhUky0UGSS25",
        "outputId": "35639a8b-73ca-4868-ee6a-879db418d11f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wd.get(\"https://www.youtube.com\")"
      ],
      "metadata": {
        "id": "FDLsIYNoR9gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install webdriver-manager"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQW4bSPxzI6C",
        "outputId": "a37a8eea-dd58-4317-c0b6-f0a9284cb4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.7/dist-packages (3.5.3)\n",
            "Requirement already satisfied: crayons in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (0.4.0)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (5.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (2.23.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from crayons->webdriver-manager) (0.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (1.25.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from selenium import webdriver\n",
        "# from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# driver = webdriver.Chrome(ChromeDriverManager().install())"
      ],
      "metadata": {
        "id": "mCfNxKqHzSOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#url ='https://www.youtube.com/c/JohnWatsonRooney/videos?view=0&sort=p&flow=grid'\n",
        "url ='https://www.youtube.com/results?search_query=smol+pp'"
      ],
      "metadata": {
        "id": "59mqB9o4qIiY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9IdmyA2_6e_"
      },
      "outputs": [],
      "source": [
        "# from selenium import webdriver\n",
        "# from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# urls = [\n",
        "#     'https://www.youtube.com/c/Freecodecamp',\n",
        "#     'https://www.youtube.com/user/thenewboston',\n",
        "#     'https://www.youtube.com/user/gotreehouse',\n",
        "#     'https://www.youtube.com/user/derekbanas',\n",
        "#     'https://www.youtube.com/channel/UCWr0mx597DnSGLFk1WfvSkQ',\n",
        "#     'https://www.youtube.com/user/ProgrammingKnowledge'\n",
        "# ]"
      ],
      "metadata": {
        "id": "wV3Lz5PLAYU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uril='https://www.youtube.com/c/Freecodecamp'\n",
        "# wd.get('{}/videos?view=0&sort=p&flow=grid'.format(uril))\n",
        "# content = wd.page_source.encode('utf-8').strip()\n",
        "# soup = BeautifulSoup(content, 'lxml')\n",
        "# print(soup.prettify())"
      ],
      "metadata": {
        "id": "iWaTWiHAGmCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# titles = soup.findAll('a',id='video-title')\n",
        "# titles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8YAydV1IQRH",
        "outputId": "611ba095-3e83-4023-f057-5c574507958e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def main():\n",
        "#     # driver = webdriver.Chrome()\n",
        "#     for url in urls:\n",
        "#         wd.get('{}/videos?view=0&sort=p&flow=grid'.format(url))\n",
        "#         content = wd.page_source.encode('utf-8').strip()\n",
        "#         soup = BeautifulSoup(content, 'lxml')\n",
        "#         titles = soup.findAll('a',id='video-title')\n",
        "#         views = soup.findAll('span',class_='style-scope ytd-grid-video-renderer')\n",
        "#         video_urls = soup.findAll('a',id='video-title')\n",
        "#         print(titles)\n",
        "#         print(views)\n",
        "#         print('Channel: {}'.format(url))\n",
        "#         i = 0 # views and time\n",
        "#         j = 0 # urls\n",
        "#         for title in titles[:10]:\n",
        "#             print('\\n{}\\t{}\\t{}\\thttps://www.youtube.com{}'.format(title.text, views[i].text, views[i+1].text, video_urls[j].get('href')))\n",
        "#             i+=2\n",
        "#             j+=1"
      ],
      "metadata": {
        "id": "ye37zWlpAcF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main()"
      ],
      "metadata": {
        "id": "gh58HsfoAgQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium.common.exceptions import NoSuchElementException\n",
        "import time"
      ],
      "metadata": {
        "id": "DvEN_7fg7Pzi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wd.get(url)"
      ],
      "metadata": {
        "id": "QkO_ujPcqTdb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time.sleep(2) # seconds until popup appears\n",
        "\n",
        "try: # 2 different popups\n",
        "#     frame = driver.find_element_by_xpath('//*[@id=\"cnsw\"]/iframe')\n",
        "#     driver.switch_to.frame(frame)\n",
        "    wd.find_element_by_xpath('//*[@id=\"yDmH0d\"]/c-wiz/div/div/div/div[2]/div[1]/div[4]/form/div/div/button').click()\n",
        "\n",
        "except NoSuchElementException:\n",
        "    print(\"no such element\")\n",
        "#     driver.find_element_by_xpath('//*[@id=\"zV9nZe\"]').click()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNCv8xkN7SB2",
        "outputId": "185d423d-a24b-4382-8e72-f55e63b44e1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no such element\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=wd.find_element_by_xpath('/html/body/ytd-app/div/ytd-page-manager/ytd-search/div[1]/ytd-two-column-search-results-renderer/div/ytd-section-list-renderer/div[2]/ytd-item-section-renderer/div[3]/ytd-video-renderer[2]')\n",
        "\n"
      ],
      "metadata": {
        "id": "4usQ4m_h7Jyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac6375b-fd77-4e14-ee13-31b20eca9691"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RcoMSXw2B1Nu",
        "outputId": "fb28b31e-cbec-41f7-fae7-3cc75895d7dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'8:07\\nSmall pp Memes\\n13K views\\n9 months ago\\nMemelord 69\\n... THE TAGS small pp memes, small pp song, small pp club voicemail, small pp, small pp funny, small pp meme, smol pp, smol pp'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# style-scope ytd-grid-video-renderer\n",
        "\n",
        "#title //*[@id=\"video-title\"]\n",
        "#views //*[@id=\"metadata-line\"]/span[1]\n",
        "#months ago //*[@id=\"metadata-line\"]/span[2]"
      ],
      "metadata": {
        "id": "UfDssqR6raN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos = wd.find_elements_by_class_name('style-scope ytd-grid-video-renderer')\n",
        "#videos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M5QTX-mtCsS",
        "outputId": "e0f0fa90-f4ce-4d5a-912a-f263028a2c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for video in videos:\n",
        "  title= video.find_element_by_xpath('.//*[@id=\"video-title\"]').text\n",
        "  views= video.find_element_by_xpath('.//*[@id=\"metadata-line\"]/span[1]').text\n",
        "  when= video.find_element_by_xpath('.//*[@id=\"metadata-line\"]/span[2]').text\n",
        "  print(\"saqma\",title,views,when)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMgJ00jvtRbX",
        "outputId": "af3cf42d-612a-49b0-e16c-3d072e0ae224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/selenium/webdriver/remote/webelement.py:393: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
            "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saqma Scrapy for Beginners - A Complete How To Example Web Scraping Project 85K views 1 year ago\n",
            "saqma How to SCRAPE DYNAMIC websites with Selenium 66K views 2 years ago\n",
            "saqma Web Scraping with Python: Ecommerce Product Pages. In Depth including troubleshooting 61K views 1 year ago\n",
            "saqma How to Rotate Proxies with Python 47K views 1 year ago\n",
            "saqma Web Scraping: HTML Tables with Python 40K views 2 years ago\n",
            "saqma How to Scrape and Download ALL images from a webpage with Python 37K views 1 year ago\n",
            "saqma How I use SELENIUM to AUTOMATE the Web with PYTHON. Pt1 31K views 2 years ago\n",
            "saqma How I Scrape JAVASCRIPT websites with Python 29K views 1 year ago\n",
            "saqma How to Web Scrape Indeed with Python - Extract Job Information to CSV 28K views 1 year ago\n",
            "saqma Scrape Amazon NEW METHOD with Python 2020 26K views 1 year ago\n",
            "saqma How I Scrape multiple pages on Amazon with Python, Requests & BeautifulSoup 26K views 1 year ago\n",
            "saqma How to scrape SPORTS STATS websites with Python 25K views 1 year ago\n",
            "saqma How I WEBSCRAPE Websites with LOGINS - Python Tutorial 22K views 2 years ago\n",
            "saqma Beautifulsoup vs Selenium vs Scrapy - Which tool for web scraping in 2021? 22K views 1 year ago\n",
            "saqma How I save my Scraped Data to a Database with Python! Beginners sqlite3 tutorial 20K views 1 year ago\n",
            "saqma How Web Scrape Multiple Pages with ONE Function with Python 20K views 1 year ago\n",
            "saqma Render Dynamic Pages - Web Scraping Product Links with Python 19K views 1 year ago\n",
            "saqma User Agent Switching - Python Web Scraping 19K views 1 year ago\n",
            "saqma Scrape HTML tables easily with Pandas and Python 18K views 1 year ago\n",
            "saqma Web Scraping NEWS Articles with Python 18K views 1 year ago\n",
            "saqma Python Web Scraping: JSON in SCRIPT tags 18K views 1 year ago\n",
            "saqma How to Scrape Stock Prices from Yahoo Finance with Python 18K views 1 year ago\n",
            "saqma Always Check for the Hidden API when Web Scraping 18K views 6 months ago\n",
            "saqma Automate Excel Work with Python and Pandas 16K views 7 months ago\n",
            "saqma How I Scrape Amazon Reviews using Python, Requests & BeautifulSoup 15K views 1 year ago\n",
            "saqma Crawl and Follow links with SCRAPY - Web Scraping with Python Project 15K views 10 months ago\n",
            "saqma Scrapy Splash for Beginners - Example, Settings and Shell Use 14K views 1 year ago\n",
            "saqma EBAY Price Tracking with Python, Beautifulsoup and Requests 14K views 1 year ago\n",
            "saqma Python CSV files - with PANDAS 14K views 2 years ago\n",
            "saqma API Endpoints? Get data from the web easily with PYTHON 13K views 1 year ago\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##consent fix"
      ],
      "metadata": {
        "id": "JVeCLIxG6hAt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}