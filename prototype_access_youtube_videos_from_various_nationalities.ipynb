{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prototype_access_youtube_videos_from_various_nationalities.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXwsq6O1CgJph4GWDNucCA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/El-Nico/accent-classification-using-scraped-youtube-data-CCT-capstone-project/blob/main/prototype_access_youtube_videos_from_various_nationalities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# !pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz00DP5IAvQM",
        "outputId": "5be44b26-cc71-4ffa-a81b-1e4d00240c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHmB7ubRBOfc",
        "outputId": "b2295f55-f87d-4134-a834-a9826aa32d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.1.0)\n",
            "Requirement already satisfied: urllib3[secure]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.26.8)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.20.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
            "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (36.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
            "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (22.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (3.10.0.2)\n",
            "Get:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:9 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:11 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,827 kB]\n",
            "Get:12 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [937 kB]\n",
            "Ign:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:15 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Fetched 2,854 kB in 2s (1,341 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (97.0.4692.71-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 66 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhUky0UGSS25",
        "outputId": "95a2130d-f272-4c74-9792-6c511ea4edab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wd.get(\"https://www.youtube.com\")"
      ],
      "metadata": {
        "id": "FDLsIYNoR9gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install webdriver-manager"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQW4bSPxzI6C",
        "outputId": "a37a8eea-dd58-4317-c0b6-f0a9284cb4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.7/dist-packages (3.5.3)\n",
            "Requirement already satisfied: crayons in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (0.4.0)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (5.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from webdriver-manager) (2.23.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from crayons->webdriver-manager) (0.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver-manager) (1.25.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from selenium import webdriver\n",
        "# from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# driver = webdriver.Chrome(ChromeDriverManager().install())"
      ],
      "metadata": {
        "id": "mCfNxKqHzSOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url ='https://www.youtube.com/c/JohnWatsonRooney/videos?view=0&sort=p&flow=grid'"
      ],
      "metadata": {
        "id": "59mqB9o4qIiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9IdmyA2_6e_"
      },
      "outputs": [],
      "source": [
        "# from selenium import webdriver\n",
        "# from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# urls = [\n",
        "#     'https://www.youtube.com/c/Freecodecamp',\n",
        "#     'https://www.youtube.com/user/thenewboston',\n",
        "#     'https://www.youtube.com/user/gotreehouse',\n",
        "#     'https://www.youtube.com/user/derekbanas',\n",
        "#     'https://www.youtube.com/channel/UCWr0mx597DnSGLFk1WfvSkQ',\n",
        "#     'https://www.youtube.com/user/ProgrammingKnowledge'\n",
        "# ]"
      ],
      "metadata": {
        "id": "wV3Lz5PLAYU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uril='https://www.youtube.com/c/Freecodecamp'\n",
        "# wd.get('{}/videos?view=0&sort=p&flow=grid'.format(uril))\n",
        "# content = wd.page_source.encode('utf-8').strip()\n",
        "# soup = BeautifulSoup(content, 'lxml')\n",
        "# print(soup.prettify())"
      ],
      "metadata": {
        "id": "iWaTWiHAGmCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# titles = soup.findAll('a',id='video-title')\n",
        "# titles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8YAydV1IQRH",
        "outputId": "611ba095-3e83-4023-f057-5c574507958e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def main():\n",
        "#     # driver = webdriver.Chrome()\n",
        "#     for url in urls:\n",
        "#         wd.get('{}/videos?view=0&sort=p&flow=grid'.format(url))\n",
        "#         content = wd.page_source.encode('utf-8').strip()\n",
        "#         soup = BeautifulSoup(content, 'lxml')\n",
        "#         titles = soup.findAll('a',id='video-title')\n",
        "#         views = soup.findAll('span',class_='style-scope ytd-grid-video-renderer')\n",
        "#         video_urls = soup.findAll('a',id='video-title')\n",
        "#         print(titles)\n",
        "#         print(views)\n",
        "#         print('Channel: {}'.format(url))\n",
        "#         i = 0 # views and time\n",
        "#         j = 0 # urls\n",
        "#         for title in titles[:10]:\n",
        "#             print('\\n{}\\t{}\\t{}\\thttps://www.youtube.com{}'.format(title.text, views[i].text, views[i+1].text, video_urls[j].get('href')))\n",
        "#             i+=2\n",
        "#             j+=1"
      ],
      "metadata": {
        "id": "ye37zWlpAcF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main()"
      ],
      "metadata": {
        "id": "gh58HsfoAgQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium.common.exceptions import NoSuchElementException\n",
        "import time"
      ],
      "metadata": {
        "id": "DvEN_7fg7Pzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wd.get(url)"
      ],
      "metadata": {
        "id": "QkO_ujPcqTdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time.sleep(2) # seconds until popup appears\n",
        "\n",
        "try: # 2 different popups\n",
        "#     frame = driver.find_element_by_xpath('//*[@id=\"cnsw\"]/iframe')\n",
        "#     driver.switch_to.frame(frame)\n",
        "    wd.find_element_by_xpath('//*[@id=\"yDmH0d\"]/c-wiz/div/div/div/div[2]/div[1]/div[4]/form/div/div/button').click()\n",
        "\n",
        "except NoSuchElementException:\n",
        "    print(\"no such element\")\n",
        "#     driver.find_element_by_xpath('//*[@id=\"zV9nZe\"]').click()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNCv8xkN7SB2",
        "outputId": "8dee858d-7781-42f7-e62b-3c95d9c0f816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4usQ4m_h7Jyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# style-scope ytd-grid-video-renderer\n",
        "\n",
        "#title //*[@id=\"video-title\"]\n",
        "#views //*[@id=\"metadata-line\"]/span[1]\n",
        "#months ago //*[@id=\"metadata-line\"]/span[2]"
      ],
      "metadata": {
        "id": "UfDssqR6raN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos = wd.find_elements_by_class_name('style-scope ytd-grid-video-renderer')\n",
        "#videos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M5QTX-mtCsS",
        "outputId": "e0f0fa90-f4ce-4d5a-912a-f263028a2c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for video in videos:\n",
        "  title= video.find_element_by_xpath('.//*[@id=\"video-title\"]').text\n",
        "  views= video.find_element_by_xpath('.//*[@id=\"metadata-line\"]/span[1]').text\n",
        "  when= video.find_element_by_xpath('.//*[@id=\"metadata-line\"]/span[2]').text\n",
        "  print(\"saqma\",title,views,when)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMgJ00jvtRbX",
        "outputId": "af3cf42d-612a-49b0-e16c-3d072e0ae224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/selenium/webdriver/remote/webelement.py:393: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
            "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saqma Scrapy for Beginners - A Complete How To Example Web Scraping Project 85K views 1 year ago\n",
            "saqma How to SCRAPE DYNAMIC websites with Selenium 66K views 2 years ago\n",
            "saqma Web Scraping with Python: Ecommerce Product Pages. In Depth including troubleshooting 61K views 1 year ago\n",
            "saqma How to Rotate Proxies with Python 47K views 1 year ago\n",
            "saqma Web Scraping: HTML Tables with Python 40K views 2 years ago\n",
            "saqma How to Scrape and Download ALL images from a webpage with Python 37K views 1 year ago\n",
            "saqma How I use SELENIUM to AUTOMATE the Web with PYTHON. Pt1 31K views 2 years ago\n",
            "saqma How I Scrape JAVASCRIPT websites with Python 29K views 1 year ago\n",
            "saqma How to Web Scrape Indeed with Python - Extract Job Information to CSV 28K views 1 year ago\n",
            "saqma Scrape Amazon NEW METHOD with Python 2020 26K views 1 year ago\n",
            "saqma How I Scrape multiple pages on Amazon with Python, Requests & BeautifulSoup 26K views 1 year ago\n",
            "saqma How to scrape SPORTS STATS websites with Python 25K views 1 year ago\n",
            "saqma How I WEBSCRAPE Websites with LOGINS - Python Tutorial 22K views 2 years ago\n",
            "saqma Beautifulsoup vs Selenium vs Scrapy - Which tool for web scraping in 2021? 22K views 1 year ago\n",
            "saqma How I save my Scraped Data to a Database with Python! Beginners sqlite3 tutorial 20K views 1 year ago\n",
            "saqma How Web Scrape Multiple Pages with ONE Function with Python 20K views 1 year ago\n",
            "saqma Render Dynamic Pages - Web Scraping Product Links with Python 19K views 1 year ago\n",
            "saqma User Agent Switching - Python Web Scraping 19K views 1 year ago\n",
            "saqma Scrape HTML tables easily with Pandas and Python 18K views 1 year ago\n",
            "saqma Web Scraping NEWS Articles with Python 18K views 1 year ago\n",
            "saqma Python Web Scraping: JSON in SCRIPT tags 18K views 1 year ago\n",
            "saqma How to Scrape Stock Prices from Yahoo Finance with Python 18K views 1 year ago\n",
            "saqma Always Check for the Hidden API when Web Scraping 18K views 6 months ago\n",
            "saqma Automate Excel Work with Python and Pandas 16K views 7 months ago\n",
            "saqma How I Scrape Amazon Reviews using Python, Requests & BeautifulSoup 15K views 1 year ago\n",
            "saqma Crawl and Follow links with SCRAPY - Web Scraping with Python Project 15K views 10 months ago\n",
            "saqma Scrapy Splash for Beginners - Example, Settings and Shell Use 14K views 1 year ago\n",
            "saqma EBAY Price Tracking with Python, Beautifulsoup and Requests 14K views 1 year ago\n",
            "saqma Python CSV files - with PANDAS 14K views 2 years ago\n",
            "saqma API Endpoints? Get data from the web easily with PYTHON 13K views 1 year ago\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##consent fix"
      ],
      "metadata": {
        "id": "JVeCLIxG6hAt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}